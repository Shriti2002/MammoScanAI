# -*- coding: utf-8 -*-
"""Breast_Cancer_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12yN0-_fYfa6b6oM3xzIx6NHue3W7p3Fn
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score,confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

data = pd.read_csv("data.csv")

data.head()

data.info()

pd.set_option('float_format', '{:f}'.format)
data.describe().T

# Since Unnamed: 32 column doesn't have any value we are dropping it
data.drop(['Unnamed: 32', 'id'],axis = 1 ,inplace = True)

data_quality_report = pd.DataFrame(columns = ['feature','count', 'missing %','unique values' ,'mean', 'std', 'min', 'Q1', 'median', 'Q3', 'max', 'IQR'])

for i, (f, ser) in enumerate(data._get_numeric_data().items()):
    Q1 = ser.quantile(0.25)
    Q3 = ser.quantile(0.75)

    # Create a dictionary to store the values for the current row
    row_data = {
        'feature': f,
        'count': ser.count(),
        'missing %': (ser.isnull().sum()/ser.size)*100,
        'unique values': ser.unique().size,
        'mean': ser.mean(),
        'std': ser.std(),
        'min': ser.min(),
        'Q1': Q1,
        'median': ser.median(),
        'Q3': Q3,
        'max': ser.max(),
        'IQR': Q3 - Q1
    }

    # Append the row data as a new row to the DataFrame
    data_quality_report = pd.concat([data_quality_report, pd.DataFrame([row_data])], ignore_index=True)

data_quality_report

data.isnull().sum().sum()

data['diagnosis'].value_counts().plot(kind = 'bar')

corr = data.corr()
cmap = sns.diverging_palette(220, 10, as_cmap=True)
f, ax = plt.subplots(figsize=(21, 19))
sns.heatmap(corr, cmap=cmap, center=0,annot = True,
            square=True, linewidths=.5, cbar_kws={"shrink": .5});

# Convert 'diagnosis' column to numerical representation before calculating correlation
data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})  # Map 'M' to 1 and 'B' to 0

# Calculate the correlation matrix
corr = data.corr()

# Proceed with creating the heatmap
cmap = sns.diverging_palette(220, 10, as_cmap=True)
f, ax = plt.subplots(figsize=(21, 19))
sns.heatmap(corr, cmap=cmap, center=0, annot=True,
            square=True, linewidths=.5, cbar_kws={"shrink": .5});

corr.head()

#It is taking a lot of time to execute this function as there are 30 features. If you are running this on TPU or something then uncomment and run

sns.pairplot(data);

class_mapping = {label:idx for idx,label in enumerate(np.unique(data['diagnosis']))}
data['diagnosis'] = data['diagnosis'].map(class_mapping)
data['diagnosis'].value_counts()

#data = data[selected_columns]
len(data.columns)

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
# find best scored k features
select_feature = SelectKBest(chi2, k=10).fit(data.drop('diagnosis',axis = 1 ), data['diagnosis'])

print('Score list:', select_feature.scores_)
print('Feature list:', data.columns)
select_feature

select_feature.transform(data.drop('diagnosis',axis = 1))

selected_columns = np.array(data.drop('diagnosis',axis = 1).columns)[select_feature.get_support()]
selected_columns

ABT = pd.DataFrame(select_feature.transform(data.drop('diagnosis',axis = 1)),columns=selected_columns)
y = data.diagnosis

ABT.head()

ABT.describe().T

compare = pd.DataFrame(index=['RandomForest', 'SVM', 'LogisticRegression', 'kNN', 'Naive Bayes'],
                      columns=['Accuracy', 'f1 score', 'Precision', 'Recall'])
compare

X_train, X_test, y_train, y_test = train_test_split(ABT, y, test_size=0.2, random_state=0)
X_train, X_v, y_train, y_v = train_test_split(X_train, y_train, test_size=0.2, random_state=0)

rf = RandomForestClassifier(criterion='gini', n_estimators=1000, max_depth=3, random_state=0, n_jobs=-1)
rf = rf.fit(X_train,y_train)

y_pred = rf.predict(X_v)
print(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')
print(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')
print(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')
print(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')
confmat = confusion_matrix(y_v,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)
f1 = f1_score(y_true=y_test, y_pred=y_pred)
precision = precision_score(y_true=y_test, y_pred=y_pred)
recall = recall_score(y_true=y_test, y_pred=y_pred)


compare.loc['RandomForest', :] = (accuracy, f1, precision, recall)

print(f'Accuracy on test set is {accuracy}')
print(f'f1 score on test set is {f1}')
print(f'Precision on test set is {precision}')
print(f'Recall on test set is {recall}')


confmat = confusion_matrix(y_test,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

from sklearn import preprocessing

min_max_scaler = preprocessing.MinMaxScaler()
NormalizedABT = min_max_scaler.fit_transform(ABT)
NormalizedABT=pd.DataFrame(NormalizedABT, columns=selected_columns)
X_train, X_test, y_train, y_test = train_test_split(NormalizedABT, y, test_size=0.2, random_state=0)
X_train, X_v, y_train, y_v = train_test_split(X_train, y_train, test_size=0.2, random_state=0)
NormalizedABT.describe().T

from sklearn import svm

clf = svm.SVC().fit(X_train, y_train)
y_pred = clf.predict(X_v)

print(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')
print(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')
print(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')
print(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')

confmat = confusion_matrix(y_v,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)
f1 = f1_score(y_true=y_test, y_pred=y_pred)
precision = precision_score(y_true=y_test, y_pred=y_pred)
recall = recall_score(y_true=y_test, y_pred=y_pred)

compare.loc['SVM', :] = (accuracy, f1, precision, recall)

print(f'Accuracy on test set is {accuracy}')
print(f'f1 score on test set is {f1}')
print(f'Precision on test set is {precision}')
print(f'Recall on test set is {recall}')

confmat = confusion_matrix(y_test,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(random_state=0).fit(X_train, y_train)
y_pred = clf.predict(X_v)

print(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')
print(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')
print(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')
print(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')

confmat = confusion_matrix(y_v,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)
f1 = f1_score(y_true=y_test, y_pred=y_pred)
precision = precision_score(y_true=y_test, y_pred=y_pred)
recall = recall_score(y_true=y_test, y_pred=y_pred)

compare.loc['LogisticRegression', :] = (accuracy, f1, precision, recall)

print(f'Accuracy on test set is {accuracy}')
print(f'f1 score on test set is {f1}')
print(f'Precision on test set is {precision}')
print(f'Recall on test set is {recall}')


confmat = confusion_matrix(y_test,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier(n_neighbors=19).fit(X_train, y_train)

y_pred = clf.predict(X_v)

print(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')
print(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')
print(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')
print(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')

confmat = confusion_matrix(y_v,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)
f1 = f1_score(y_true=y_test, y_pred=y_pred)
precision = precision_score(y_true=y_test, y_pred=y_pred)
recall = recall_score(y_true=y_test, y_pred=y_pred)

compare.loc['kNN', :] = (accuracy, f1, precision, recall)

print(f'Accuracy on test set is {accuracy}')
print(f'f1 score on test set is {f1}')
print(f'Precision on test set is {precision}')
print(f'Recall on test set is {recall}')

confmat = confusion_matrix(y_test,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

from sklearn.naive_bayes import GaussianNB

clf = GaussianNB().fit(X_train, y_train)

y_pred = clf.predict(X_v)

print(f'Accuracy on validation set is {accuracy_score(y_v,y_pred)}')
print(f'f1 score on validation set is {f1_score(y_true=y_v, y_pred=y_pred)}')
print(f'Precision on validation set is {precision_score(y_true=y_v, y_pred=y_pred)}')
print(f'Recall on validation set is {recall_score(y_true=y_v, y_pred=y_pred)}')

confmat = confusion_matrix(y_v,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)
f1 = f1_score(y_true=y_test, y_pred=y_pred)
precision = precision_score(y_true=y_test, y_pred=y_pred)
recall = recall_score(y_true=y_test, y_pred=y_pred)

compare.loc['Naive Bayes', :] = (accuracy, f1, precision, recall)

print(f'Accuracy on test set is {accuracy}')
print(f'f1 score on test set is {f1}')
print(f'Precision on test set is {precision}')
print(f'Recall on test set is {recall}')

confmat = confusion_matrix(y_test,y_pred)
sns.heatmap(confmat,annot=True,fmt="d")

compare

